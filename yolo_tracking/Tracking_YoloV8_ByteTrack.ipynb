{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "488f589d",
   "metadata": {},
   "source": [
    "# Tracking de objetos con YoloV8 y Bytetrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd964d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics==8.0.84\n",
    "# !pip install Cython\n",
    "# !pip install numpy\n",
    "# !pip install lap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d659ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# esto es para evitar un error en Windows: OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics.nn.autobackend import AutoBackend\n",
    "from ultralytics.yolo.utils.plotting import Annotator, colors\n",
    "import torch\n",
    "from bytetrack.byte_tracker import BYTETracker\n",
    "from ultralytics.yolo.data.dataloaders.stream_loaders import LoadImages\n",
    "from ultralytics.yolo.utils.ops import non_max_suppression, scale_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3439399",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_thres = 0.25\n",
    "iou_thres = 0.45\n",
    "classes = None\n",
    "agnostic_nms = False\n",
    "max_det = 1000\n",
    "line_thickness = 2\n",
    "half = False\n",
    "imgsz = (640, 640)\n",
    "vid_stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcad7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vid = True\n",
    "video_file = \"skateboard_02.mp4\"\n",
    "vid_writer = None\n",
    "save_path = video_file[:-4] + \"_output.mp4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac7c665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model = AutoBackend(\"yolov8n.pt\")\n",
    "model.warmup()\n",
    "stride, names, pt = model.stride, model.names, model.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ea3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bytetracker = BYTETracker(\n",
    "    track_thresh=0.6, match_thresh=0.8, track_buffer=120, frame_rate=30\n",
    ")\n",
    "tracker = bytetracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b9178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LoadImages(\n",
    "    video_file,\n",
    "    imgsz=imgsz,\n",
    "    stride=stride,\n",
    "    auto=pt,\n",
    "    transforms=None,\n",
    "    vid_stride=vid_stride,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c8962e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_idx, batch in enumerate(dataset):\n",
    "    path, im, im0s, vid_cap, s = batch\n",
    "    detections = np.empty((0, 5))\n",
    "    im = torch.from_numpy(im).to(\"cpu\")\n",
    "    im = im.half() if half else im.float()  # uint8 to fp16/32\n",
    "    im /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    im = torch.unsqueeze(im, 0)\n",
    "\n",
    "    result = model(im)\n",
    "\n",
    "    p = non_max_suppression(\n",
    "        result, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det\n",
    "    )\n",
    "\n",
    "    for i, det in enumerate(p):\n",
    "        p, im0, _ = path, im0s.copy(), getattr(dataset, \"frame\", 0)\n",
    "\n",
    "        if det is not None and len(det):\n",
    "            det[:, :4] = scale_boxes(\n",
    "                im.shape[2:], det[:, :4], im0.shape\n",
    "            ).round()  # rescale boxes to im0 size\n",
    "\n",
    "        track_result = tracker.update(det.cpu(), im0)\n",
    "\n",
    "        annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "\n",
    "        # draw boxes for visualization\n",
    "        if len(track_result) > 0:\n",
    "            for j, (output) in enumerate(track_result):\n",
    "                bbox = output[0:4]\n",
    "                id = output[4]\n",
    "                cls = output[5]\n",
    "                conf = output[6]\n",
    "\n",
    "                c = int(cls)  # integer class\n",
    "                id = int(id)  # integer id\n",
    "                label = f\"{id} {names[c]} {conf:.2f}\"\n",
    "                color = colors(c, True)\n",
    "                annotator.box_label(bbox, label, color=color)\n",
    "\n",
    "    # Stream results\n",
    "    im0 = annotator.result()\n",
    "    cv2.imshow(str(p), im0)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):  # 1 millisecond\n",
    "        exit()\n",
    "\n",
    "    if save_vid:\n",
    "        if not vid_writer:\n",
    "            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            vid_writer = cv2.VideoWriter(\n",
    "                save_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h)\n",
    "            )\n",
    "\n",
    "        vid_writer.write(im0)\n",
    "\n",
    "if vid_writer:\n",
    "    vid_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4296fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
